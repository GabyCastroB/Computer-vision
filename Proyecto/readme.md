# ğŸ‘ï¸â€ğŸ—¨ï¸ VisiÃ³n por Computadora para la Movilidad de Personas Invidentes en Ciudades  

Este proyecto fue desarrollado en el curso **VisiÃ³n de MÃ¡quina** de la Universidad Nacional de Colombia.  
El objetivo principal es implementar un sistema de **detecciÃ³n y clasificaciÃ³n de objetos urbanos** que apoye la movilidad de personas con discapacidad visual, usando **redes neuronales convolucionales** y **procesamiento de imÃ¡genes**.  

---

## ğŸ“Œ Resumen  
El proyecto consiste en el desarrollo de un software basado en **YOLOv5** entrenado sobre un dataset urbano (CARLA Dataset), con el fin de identificar objetos clave en entornos de ciudad:  

- ğŸš¦ SemÃ¡foros (rojo, amarillo, verde)  
- ğŸš¸ Pasos peatonales  
- ğŸš— VehÃ­culos  
- ğŸš² Bicicletas  
- ğŸï¸ Motocicletas  
- ğŸš· SeÃ±ales de trÃ¡nsito (30km, 60km, 90km)  
- ğŸš¶ Personas  

El sistema procesa imÃ¡genes, detecta los objetos y comunica la informaciÃ³n de manera que sirva de apoyo a personas con discapacidad visual.

---

## ğŸ¯ Alcance  
- El modelo estÃ¡ diseÃ±ado para **entornos urbanos**: calles, andenes, puentes, etc.  
- Se centra en objetos clave para la movilidad segura.  
- Considera variaciones de iluminaciÃ³n y horarios (dÃ­a/noche).  

---

## âš™ï¸ Herramientas y TecnologÃ­as  

- **Lenguaje principal**: Python ğŸ  
- **Frameworks de Deep Learning**: [PyTorch](https://pytorch.org/) + [Ultralytics YOLOv5](https://github.com/ultralytics/yolov5)  
- **Entorno de ejecuciÃ³n**: Google Colab  
- **GestiÃ³n de experimentos**: Comet.ml  
- **Datasets**:  
  - [COCO](https://cocodataset.org) (referencia inicial)  
  - [CARLA Dataset](https://www.kaggle.com/datasets/) (final, optimizado para trÃ¡fico y seÃ±ales)  

---

## ğŸ—‚ï¸ Base de Datos  

- **CARLA Dataset** (103 MB)  
- 10 clases de objetos relevantes para movilidad en ciudad.  
- Incluye anotaciones detalladas con **bounding boxes** y segmentaciÃ³n semÃ¡ntica.  

Ejemplo de anotaciÃ³n:  

```txt
[class_id] [x_center] [y_center] [width] [height]
3 0.512 0.624 0.214 0.198

## ğŸ–¼ï¸ Ejemplo visual (imagen + caja delimitadora)

Ejemplo de anotaciÃ³n y detecciÃ³n en el dataset:

![Ejemplo dataset](docs/img/dataset_example.png)

---

## ğŸ› ï¸ Preprocesamiento de ImÃ¡genes  

Se aplicaron las siguientes transformaciones antes de entrenar el modelo:  

- ConversiÃ³n a **escala de grises**.  
- Redimensionamiento a **416x416 pÃ­xeles**.  
- NormalizaciÃ³n de pÃ­xeles en rango `[0,1]`.  
- NormalizaciÃ³n de **bounding boxes** al formato YOLO.  
- AplicaciÃ³n de **filtro Gaussiano** para reducciÃ³n de ruido.  

### Ejemplo:

| Imagen original | Imagen preprocesada |
|-----------------|----------------------|
| ![original](docs/img/original.png) | ![preprocesada](docs/img/preprocessed.png) |

---

## ğŸ¤– Algoritmo de DetecciÃ³n  

Se utilizÃ³ **YOLOv5** por su rapidez y precisiÃ³n en tiempo real.  

### ParÃ¡metros de entrenamiento  

- ğŸ“· **ImÃ¡genes de entrenamiento**: 1600  
- ğŸ§ª **ImÃ¡genes de validaciÃ³n**: 263  
- ğŸ“¦ **Batch size**: 16  
- ğŸ” **Epochs**: 80  
- ğŸ·ï¸ **Clases**: 10  

---

### ğŸš€ Ejemplo de entrenamiento en Google Colab  

```python
# Clonar repositorio de YOLOv5
!git clone https://github.com/ultralytics/yolov5  
%cd yolov5

# Instalar dependencias
!pip install -r requirements.txt

# Entrenamiento del modelo
!python train.py --img 416 --batch 16 --epochs 80 --data data.yaml --weights yolov5s.pt

!git clone https://github.com/ultralytics/yolov5  
%cd yolov5
!pip install -r requirements.txt

# Entrenamiento
!python train.py --img 416 --batch 16 --epochs 80 --data data.yaml --weights yolov5s.pt

## ğŸ“Š EvaluaciÃ³n de Resultados  

### ğŸ”¹ MÃ©tricas clave  

- **mAP@0.5** â‰ˆ 0.80  
- **mAP@0.95** â‰ˆ 0.65  
- **Precision** â‰ˆ 0.98  
- **Recall** â‰ˆ 0.38 *(afectado por la perspectiva y la cantidad de ejemplos)*  

ğŸ“Œ Ejemplo de matriz de confusiÃ³n:  

![Matriz de confusiÃ³n](docs/img/confusion_matrix.png)  

---

### ğŸ”¹ PÃ©rdida durante el entrenamiento  

- **Box loss, Obj loss y Cls loss** tienden a **cero** âœ…  
- Buen equilibrio entre **precisiÃ³n y recall**  

![Resultados entrenamiento](docs/img/train_results.png)  

---

## ğŸ” Resultados de PredicciÃ³n  

El modelo mostrÃ³ muy buena precisiÃ³n en condiciones estÃ¡ndar:  

| DetecciÃ³n de seÃ±ales de trÃ¡nsito y semÃ¡foro | DetecciÃ³n de vehÃ­culos y peatones |
|---------------------------------------------|----------------------------------|
| ![predicciÃ³n1](docs/img/prediction1.png)    | ![predicciÃ³n2](docs/img/prediction2.png) |

âš ï¸ En casos de **cambios de perspectiva** (ej. seÃ±ales vistas de lado), la detecciÃ³n disminuye.  

ğŸ“¹ **Videos de prueba (diurnos y nocturnos):**  
- [Video 1](https://drive.google.com/file/d/1dYb0MZngtYF1aOs30iyHLgBVDCjSrcGb/view?usp=drive_link)  
- [Video 2](https://drive.google.com/file/d/1JtuEliXzeGDHh7GctchF1vozcavJTgXZ/view?usp=drive_link)  
- [Video nocturno](https://drive.google.com/file/d/1w4rRBnKMhH7vylNyhGoPzUjA0EoiaMLA/view?usp=drive_link)  

---

## âœ… Conclusiones  

- El **preprocesamiento de imÃ¡genes** es clave para reducir el tamaÃ±o y mejorar la eficiencia.  
- El modelo es **preciso**, pero pierde robustez ante variaciones de perspectiva.  
- Los resultados sugieren un buen desempeÃ±o general, pero requieren:  
  - MÃ¡s datos en diferentes Ã¡ngulos e iluminaciÃ³n.  
  - Ajustar umbrales de decisiÃ³n para balancear precisiÃ³n y recall.  

---

## ğŸ”® Trabajo Futuro  

- Ampliar el dataset con mÃ¡s condiciones (**clima, noche, distintas perspectivas**).  
- Entrenar con mÃ¡s clases y escenarios complejos.  
- Implementar **aprendizaje continuo** para que el sistema se adapte con nuevos datos.  
- Integrar **salida auditiva en tiempo real** para asistencia directa.  

---

## ğŸ‘¨â€ğŸ’» Autores  

- **Juan NicolÃ¡s Carvajal Useche**  
- **Gabriela MarÃ­a Castro BeltrÃ¡n**  

ğŸ“ *Universidad Nacional de Colombia â€“ Facultad de IngenierÃ­a*  
ğŸ‘¨â€ğŸ« *Profesor: Flavio Augusto Prieto Ortiz*  

---
